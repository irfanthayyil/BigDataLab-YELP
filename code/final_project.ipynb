{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center; font-size: 32px\">Final project</p>\n",
    "<br>\n",
    "<p style=\"font-size:15px\">Sujay Bokil (ME17B120)<br>\n",
    "Irfan Thayyil (ME17B112)<br>\n",
    "Joel Baby Johnson(ME17B144)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking pyspark to kafka #\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries ##\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising spark session ##\n",
    "spark = SparkSession.builder.appName('yelp_project').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+------+\n",
      "|cool|funny|stars|                text|useful|\n",
      "+----+-----+-----+--------------------+------+\n",
      "|   0|    0|  5.0|I had my sofa, lo...|     0|\n",
      "|   0|    0|  5.0|Again great servi...|     0|\n",
      "|   0|    0|  4.0|Opening night, ne...|     1|\n",
      "|   0|    0|  4.0|Fun times. Great ...|     1|\n",
      "|   0|    0|  2.0|I wanted to like ...|     0|\n",
      "+----+-----+-----+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 21.2 ms, sys: 1.36 ms, total: 22.6 ms\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Reading and storing the data ##\n",
    "data = spark.read.json('gs://sgb1/yelp_train.json/*.json')\n",
    "drop_list = ['business_id','review_id','user_id','date']#'cool', 'funny''useful'\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cool: long (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  5.0|3516238|\n",
      "|  4.0|1640703|\n",
      "|  1.0|1258657|\n",
      "|  3.0| 825490|\n",
      "|  2.0| 622627|\n",
      "+-----+-------+\n",
      "\n",
      "CPU times: user 10.2 ms, sys: 0 ns, total: 10.2 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Show the counts for labels ##\n",
    "data=data.withColumnRenamed(\"stars\",\"label\")\n",
    "data.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 5503714\n",
      "Test Dataset Count: 2360001\n",
      "CPU times: user 14.4 ms, sys: 0 ns, total: 14.4 ms\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Splitting train and test data ##\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing steps ##\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"a\",\"an\",\"it\",\"its\"]\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"text_features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"t_features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "assembler = VectorAssembler(inputCols=['cool','funny','useful','t_features'],outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer,stopwordsRemover,hashingTF,idf,assembler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 16.1 ms, total: 191 ms\n",
      "Wall time: 10min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Creating a pipeline ##\n",
    "pipelineModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitting Done\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model ##\n",
    "print(\"Model Fitting Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy = ', 0.626888717420035)\n"
     ]
    }
   ],
   "source": [
    "## Evaluating trained model on test dataset ##\n",
    "evaluator =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "te_predictions =  pipelineModel.transform(testData)\n",
    "accuracy = evaluator.evaluate(te_predictions)\n",
    "print(\"Test Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "pipelineModel.save(\"gs://joel_trail/PipelineModel_LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Done\n"
     ]
    }
   ],
   "source": [
    "print('Saving Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train Accuracy = ', 0.6280051979445153, ' ,Train F score =', 0.5726721694739169)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator1 =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "tr_predictions =  pipelineModel.transform(trainingData)\n",
    "te_predictions =  pipelineModel.transform(testData)\n",
    "\n",
    "accuracy = evaluator.evaluate(tr_predictions);fscore = evaluator1.evaluate(tr_predictions)\n",
    "print(\"Train Accuracy = \",accuracy,\" ,Train F1 score =\",fscore)\n",
    "accuracy = evaluator.evaluate(te_predictions);fscore = evaluator1.evaluate(te_predictions)\n",
    "print(\"Test Accuracy = \",accuracy,\" ,Test F1 score =\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy = ', 0.626888717420035)\n"
     ]
    }
   ],
   "source": [
    "Model = PipelineModel.load(\"gs://joel_trail/PipelineModel_LR\")\n",
    "df = Model.transform(testData)\n",
    "\n",
    "evaluator =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(df)\n",
    "print(\"Test Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kafka streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing Kafka on Dataproc cluster\n",
    "# !conda install -c conda-forge kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries ##\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "from google.cloud import storage\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility functions for Kafka streaming ##\n",
    "def load_model(path_to_model):\n",
    "    return PipelineModel.load(path_to_model)\n",
    "\n",
    "def segment_by_tabs(line):\n",
    "    elements = line.split()\n",
    "    return \"\\t\".join(elements[:2]) + \"\\t\" + \\\n",
    "            \" \".join(elements[2:4]) + \"\\t\" + \\\n",
    "            \"\\t\".join(elements[4:7]) + \"\\t\" + \\\n",
    "            \" \".join(elements[7:-2]) + \\\n",
    "            \"\\t\" + \"\\t\".join(elements[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer\n",
    "\n",
    "Reads data from json files inside a given directory and streams them line by line to the given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER_IP = \"10.128.0.8\" # Internal Ip of Kafka VM\n",
    "TOPIC = \"nlp\"\n",
    "DATA_DIR = \"gs://sgb1/yelp_train.json\"\n",
    "\n",
    "\n",
    "def run_producer(broker_ip, topic, data_dir, sleep_time=0):\n",
    "    \n",
    "    producer = KafkaProducer(bootstrap_servers=[f\"{broker_ip}:9092\"])\n",
    "    \n",
    "    # Reading the data\n",
    "    bucket = data_dir.split(\"/\")[2]\n",
    "    bucket_dir = ''.join(data_dir.split(\"/\")[3:])\n",
    "    \n",
    "    client = storage.Client()\n",
    "    print(\"Reading the files ...\\n\")\n",
    "    json_files = [os.path.join(f\"gs://{bucket}\", x.name) for x in client.list_blobs(bucket, prefix=bucket_dir) \n",
    "                                                                      if x.name.endswith('.json')]\n",
    "    print(\"Files read successfully!\\n\")\n",
    "    \n",
    "    count = 1\n",
    "    n = len(json_files)\n",
    "    \n",
    "    print(f\"Writing the data to Kafka {topic} ...\\n\")\n",
    "    for fnum, fname in enumerate(json_files):\n",
    "        df = pd.read_json(fname, lines=True)\n",
    "        \n",
    "        lines = df.to_string(header=False,\n",
    "                             index=False,\n",
    "                             index_names=False).split('\\n')\n",
    "        \n",
    "        lines = [segment_by_tabs(line) for line in lines]\n",
    "        for line in lines:\n",
    "            producer.send(topic, key=str(count).encode(), value=line.encode())\n",
    "            producer.flush()\n",
    "            time.sleep(sleep_time)\n",
    "            count+=1\n",
    "    \n",
    "        print(f\"File {fnum + 1}/{n} completed.\")\n",
    "            \n",
    "    producer.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the files ...\n",
      "\n",
      "Files read successfully!\n",
      "\n",
      "Writing the data to Kafka nlp ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running the producer\n",
    "run_producer(BROKER_IP, TOPIC, DATA_DIR, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Consumer\n",
    "\n",
    "The consumer reads the streaming output data as a string line by line and converts it into a Spark dataframe. After that, it is sent to the model for getting the predictions which are then evaluated batchwise. The code below is the same as that inside the file subscriber.py which is submitted as a spark job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(df, epoch_id):\n",
    "    \"\"\"Evaluates accuracy and F1 score for a spark dataframe and prints the dataframe\n",
    "\n",
    "    Args:\n",
    "        df (spark.DataFrame): Spark dataframe\n",
    "        epoch_id (int): batch number\n",
    "    \"\"\"\n",
    "\n",
    "    if df.count() > 0:\n",
    "        eval_acc =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        eval_f1 =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Batch: {epoch_id}\")\n",
    "        print(\"-\"*50)\n",
    "        df.show(df.count())\n",
    "        print(f\"Accuracy: {eval_acc.evaluate(df):.4f}\\nF1 score: {eval_f1.evaluate(df):.4f}\")\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_inferences(broker_ip, topic, model_path):\n",
    "    \"\"\"Reads from stream and prints evaluated metrics\n",
    "\n",
    "    Args:\n",
    "        broker_ip (str): Internal IP address of Kafka VM\n",
    "        topic (str): kafka topic\n",
    "        model_path (str): path to the model in GCS bucket\n",
    "    \"\"\"\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"yelp_proj\").getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "    df = spark.readStream.format(\"kafka\").\\\n",
    "            option(\"kafka.bootstrap.servers\", f\"{broker_ip}:9092\").\\\n",
    "            option(\"subscribe\", topic).\\\n",
    "            load()\n",
    "    \n",
    "    split_cols = F.split(df.value,'\\t')\n",
    "    df = df.withColumn('cool',split_cols.getItem(1))\n",
    "    df = df.withColumn('funny',split_cols.getItem(3))\n",
    "    df = df.withColumn('stars',split_cols.getItem(5))\n",
    "    df = df.withColumn('text',split_cols.getItem(6))\n",
    "    df = df.withColumn('useful',split_cols.getItem(7))\n",
    "    \n",
    "    for col in ['cool', 'funny', 'stars', 'useful']:\n",
    "        df = df.withColumn(col, df[col].cast('float'))\n",
    "\n",
    "    df = df.withColumnRenamed(\"stars\",\"label\")\n",
    "    \n",
    "    df.createOrReplaceTempView(\"intermediate\")\n",
    "    \n",
    "    model = PipelineModel.load(model_path)\n",
    "    \n",
    "    predictions = model.transform(df)\n",
    "    \n",
    "    predictions = predictions.withColumn('correct',F.when((F.col('prediction')== F.col('label')),1).otherwise(0))\n",
    "\n",
    "    output_df = predictions[['prediction', 'label', 'correct']]\n",
    "    output_df.createOrReplaceTempView('output')\n",
    "    \n",
    "    query = output_df.writeStream.foreachBatch(eval_metrics).start()\n",
    "    query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the subscriber\n",
    "BROKER_IP = \"10.128.0.8\"\n",
    "TOPIC = \"nlp\"\n",
    "DATA_DIR = \"gs://sgb1/yelp_train.json\"\n",
    "MODEL_DIR = \"gs://sgb1/PipelineModel_LR\"\n",
    "\n",
    "get_inferences(BROKER_IP, TOPIC, MODEL_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}